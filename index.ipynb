{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Significance and P-values \n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lesson, we shall build on some of the ideas mentioned during significance testing with z-scores. Such an approach can help us associate a confidence level to our model's output which could be very important during decision making. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Interpret the p-value and regression coefficients\n",
    "* Describe model suitability in terms of obtained significance results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Let's get started\n",
    "\n",
    "We can apply the the ideas of hypothesis testing in a regression context as well as statistical inference. The general approach of hypothesis testing remains the same i.e. We develop a set of hypotheses including null hypothesis and alternative hypothesis. The way we conduct these tests is that we try to reject the null hypothesis with an associated alpha level as a threshold for calling our results significant , or otherwise. We set some statistic according to the nature of underlying data and analytical question and check the significance of our results. \n",
    "\n",
    "## Hypothesis Testing in Regression \n",
    "\n",
    "During regression, we try to measure the model parameters (coefficients ) so our null and alternative hypotheses must also get set up in those terms. Think about the simple regression experiment that we conducted on the advertising dataset. For a simple dataset like this, we can set up our hypotheses as follows:\n",
    "\n",
    "> **NULL HYPOTHESIS (Ho): There is no relationship between amount spent on TV advertisement and sales figures.**\n",
    "\n",
    "For our null hypothesis to be true, In y= mx+c , m has to be zero so y is simply equal to the intercept. \n",
    "\n",
    "> **ALTERNATIVE HYPOTHESIS (Ha): There is \"some\" relation between amount spent on TV advertisement and sales figures.**\n",
    "\n",
    "So for above, rejecting the null hypothesis would help us associate some significance with our results\n",
    "\n",
    "Just like for statistical significance, we reject the null (and thus believe the alternative) if the 95% confidence interval does not include zero for co-efficient. In other terms \n",
    "\n",
    "#### the p-value represents the probability that the coefficient is actually zero. \n",
    "\n",
    "Let's import the code from our previous lesson and see if we can check for this p value. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.stats as stats\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "data = pd.read_csv('Advertising.csv', index_col=0)\n",
    "f = 'sales~TV'\n",
    "f2 = 'sales~radio'\n",
    "model = smf.ols(formula=f, data=data).fit()\n",
    "model2 = smf.ols(formula=f2, data=data).fit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check for the p-value associated with intercept as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>sales</td>      <th>  R-squared:         </th> <td>   0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   312.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Apr 2019</td> <th>  Prob (F-statistic):</th> <td>1.47e-42</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:57:17</td>     <th>  Log-Likelihood:    </th> <td> -519.05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   200</td>      <th>  AIC:               </th> <td>   1042.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   198</td>      <th>  BIC:               </th> <td>   1049.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>    7.0326</td> <td>    0.458</td> <td>   15.360</td> <td> 0.000</td> <td>    6.130</td> <td>    7.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TV</th>        <td>    0.0475</td> <td>    0.003</td> <td>   17.668</td> <td> 0.000</td> <td>    0.042</td> <td>    0.053</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.531</td> <th>  Durbin-Watson:     </th> <td>   1.935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.767</td> <th>  Jarque-Bera (JB):  </th> <td>   0.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.089</td> <th>  Prob(JB):          </th> <td>   0.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.779</td> <th>  Cond. No.          </th> <td>    338.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  sales   R-squared:                       0.612\n",
       "Model:                            OLS   Adj. R-squared:                  0.610\n",
       "Method:                 Least Squares   F-statistic:                     312.1\n",
       "Date:                Fri, 12 Apr 2019   Prob (F-statistic):           1.47e-42\n",
       "Time:                        14:57:17   Log-Likelihood:                -519.05\n",
       "No. Observations:                 200   AIC:                             1042.\n",
       "Df Residuals:                     198   BIC:                             1049.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      7.0326      0.458     15.360      0.000       6.130       7.935\n",
       "TV             0.0475      0.003     17.668      0.000       0.042       0.053\n",
       "==============================================================================\n",
       "Omnibus:                        0.531   Durbin-Watson:                   1.935\n",
       "Prob(Omnibus):                  0.767   Jarque-Bera (JB):                0.669\n",
       "Skew:                          -0.089   Prob(JB):                        0.716\n",
       "Kurtosis:                       2.779   Cond. No.                         338.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept    1.406300e-35\n",
       "TV           1.467390e-42\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we generally ignore the p-value for the intercept. \n",
    "\n",
    "#### Interpreting results\n",
    "\n",
    "Here is how you would interpret this output\n",
    "\n",
    ">If the 95% confidence interval includes zero, the p-value for that coefficient will be greater than 0.05. If the 95% confidence interval does not include zero, the p-value will be less than 0.05. Thus, a p-value less than 0.05 is one way to decide whether there is likely a relationship between the feature and the response. \n",
    "\n",
    "Again, using 0.05 as the cutoff is just a convention.\n",
    "\n",
    "In this case, the p-value for TV is far less than 0.05, and so we believe that there is a relationship between TV ads and Sales. With alpha set to 0.05, we can claim to have 95% confidence on the outcome.  \n",
    "Try running above and check for p values for `radio` and see how would interpret the outcome. \n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "You are encouraged to visit following links to see more examples and explanations around:hypothesis testing in regression \n",
    "\n",
    "[Hypothesis Test for Regression Slope](https://stattrek.com/regression/slope-test.aspx)\n",
    "\n",
    "[Regression Continued](http://www.stat.ucla.edu/~cochran/stat10/winter/lectures/lect18.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this lesson, we saw how to apply the ideas of hypothesis testing in regression analysis to associate significance and confidence level with our model. We used this with our previous regression model to check the association. In the next lab, we shall combine all the ideas around simple linear regression with ols on a slightly more complex dataset with a much greater number of features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
